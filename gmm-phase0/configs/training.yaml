# Training Configuration for Phase 0 Epistemic Gap Detection

training:
  # Model selection (from model.yaml)
  model_key: "primary"  # primary | secondary | tertiary

  # Basic training parameters
  learning_rate: 5.0e-5
  batch_size: 16
  gradient_accumulation_steps: 2
  num_epochs: 3
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0

  # Learning rate scheduler
  lr_scheduler_type: "cosine"

  # Logging
  logging_steps: 10
  eval_steps: 500
  save_steps: 1000
  save_total_limit: 3

  # Evaluation
  eval_strategy: "steps"
  eval_accumulation_steps: 10
  load_best_model_at_end: true
  metric_for_best_model: "f1"
  greater_is_better: true

  # Mixed precision
  fp16: false
  bf16: true

  # Gradient checkpointing
  gradient_checkpointing: true

  # Random seed
  seed: 42

# Epistemic loss configuration
epistemic_loss:
  # Lambda hyperparameter sweep
  lambda_sweep:
    - 0.3
    - 0.5
    - 0.7

  # For single run, use this lambda
  default_lambda: 0.5

  # Loss components
  use_language_modeling_loss: true
  use_signal_loss: true

# Data configuration
data:
  train_file: "data/splits/stage_a/train.jsonl"
  val_file: "data/splits/stage_a/val.jsonl"
  test_file: "data/splits/stage_a/test.jsonl"

  # Data loading
  num_workers: 4
  prefetch_factor: 2

  # Preprocessing
  max_context_length: 1024
  max_question_length: 128
  max_answer_length: 256

# Output configuration
output:
  output_dir: "results/checkpoints/stage_a"
  logging_dir: "results/logs/stage_a"
  run_name: "stage_a_epistemic_gap_detection"

# Weights & Biases (optional)
wandb:
  enabled: false
  project: "gmm-phase0"
  entity: null  # Set to your W&B username/team
  tags:
    - "stage-a"
    - "epistemic-gap-detection"
    - "synthetic-data"

# Experimental ablations
ablations:
  # Model size comparison
  model_sizes:
    - "primary"
    - "secondary"
    - "tertiary"

  # Lambda sweep for epistemic loss
  lambda_values:
    - 0.1
    - 0.3
    - 0.5
    - 0.7
    - 1.0

  # Data size learning curves
  data_sizes:
    - 1000
    - 5000
    - 10000
    - 25000
    - 50000

  # Difficulty tiers
  difficulty_tiers:
    - "easy"
    - "medium"
    - "hard"
